

from datetime import datetime
from random import random
from bs4 import BeautifulSoup

import requests
import base64
import argparse

BASE_URLS = [
    "http://jandan.net/pic",
    "http://jandan.net/treehole",
    "http://jandan.net/qa",
]

emojilist = ["ğŸ˜»", "ğŸ¸", "ğŸ‘½", "âš•ï¸", "â¤ï¸", "ğŸ‘‘"]

HELP_TEXT = """
me_in_jiandan v1.1 \033[0;34mæ³¨ï¼š\033[0m
æ— èŠå›¾æ€»é¡µæ•°çº¦ä¸º180ï¼Œæ ‘æ´çº¦ä¸º80ï¼Œé—®ç­”çº¦ä¸º10
è‹¥å‘½ä»¤è¡Œæ”¯æŒï¼Œå¯ä»¥â€œctrl+ç‚¹å‡»â€æ‰“å¼€url"""


class Configure:
    def __init__(self, userName: str, maxPages: int, isVerbose: bool) -> None:
        self.userName = userName
        self.maxPages = maxPages
        self.isVerbose = isVerbose

    def __repr__(self) -> str:
        return f"""
[å½“å‰é…ç½®]
userName:   {self.userName}
maxPages:   {self.maxPages}
isVerbose:  {self.isVerbose}
        """


class Crawler:
    def __init__(self, base_url, configure: Configure) -> None:
        self.configure = configure
        self.base_url = base_url
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; rv:91.0) Gecko/20100101 Firefox/91.0"
        }
        self.results = list()
        self.curpage = 0

    def get_max_pages(self, raw: BeautifulSoup) -> int:
        try:
            return int(
                str(raw.find_all(class_="current-comment-page")[0])
                .split("[")[-1]
                .split("]")[0]
            )
        except Exception as e:
            print(e if self.configure.isVerbose else "å‡ºé”™äº†")

    def find_post_in_page(self, url: str, page: BeautifulSoup) -> list:
        result_map = []
        result = []
        for comment in [
            x
            for x in page.select(".commentlist>li")
            if self.configure.userName in str(x.select(".author>strong"))
        ]:
            try:
                result_map.append(
                    {
                        "type": url.split("jandan.net/")[1].split("/")[0],
                        "url": "http://jandan.net/t/"
                        + comment.select(".righttext>a")[0].text,
                        "oo": comment.select(".tucao-like-container")[0]
                        .select("span")[0]
                        .text,
                        "xx": comment.select(".tucao-unlike-container")[0]
                        .select("span")[0]
                        .text,
                        "tucao": comment.select(".tucao-btn")[0].text,
                    }
                )
            except IndexError as e:
                if self.configure.isVerbose:
                    print(e)
                continue
        for jsonitem in result_map:
            result.append(
                f"{jsonitem['url']}\too {jsonitem['oo']}\t xx {jsonitem['xx']}\t{jsonitem['tucao']}"
            )
        if self.configure.isVerbose:
            print(f"Page {self.curpage} Found {len(result)} item(s).")
        else:
            if len(result) != 0:
                emoji = emojilist[int((random() * 100)) % len(emojilist)]
                # emoji = emojilist[len(result)]
                print(f"Page {self.curpage}: {len(result)} " + emoji)
        return result

    def craw(self) -> list:
        bs = BeautifulSoup(
            requests.get(self.base_url, headers=self.headers).text, "html.parser"
        )
        self.max_pages = self.get_max_pages(bs)

        crawpagecount = self.configure.maxPages
        if self.configure.isVerbose:
            print("âš¡crawpagecount:" + str(crawpagecount))

        for i in range(self.max_pages, self.max_pages - crawpagecount, -1):
            if i < 1:
                break
            url = (
                self.base_url
                + "/"
                + base64.urlsafe_b64encode(
                    (
                        datetime.now().strftime("%Y%m%d").__str__() + "-" + str(i)
                    ).encode()
                ).decode()
            )
            self.curpage = i
            try:
                resp = requests.get(url, headers=self.headers)
            except Exception as e:
                print(
                    "Something went wrong!" + e
                    if self.configure.isVerbose
                    else "Something went wrong!"
                )
            if not resp.ok:
                print("Oops! Something went wrong!")
                continue
            # if pic or treehole
            self.results += self.find_post_in_page(
                url, BeautifulSoup(resp.text, "html.parser")
            )
        return self.results


def process_arguments():
    parser = argparse.ArgumentParser(description=HELP_TEXT)
    parser.add_argument(
        "--username",  # ç”¨æˆ·åè®¾ç½®ï¼Œå¿…å¡«ï¼Œæ¨èä½¿ç”¨å…¨åï¼Œå› ä¸ºæ˜¯æ¨¡ç³ŠåŒ¹é…çš„ã€‚
        "-u",
        metavar="Username",
        type=str,
        action="store",
        required=True,
        help="ç›®æ ‡ç”¨æˆ·å",
        dest="userName",
    )
    parser.add_argument(
        "--max-pages",  # çˆ¬å–çš„æœ€å¤§é¡µæ•°ï¼Œè¶Šå¤šè¶Šå¡ï¼Œå› ä¸ºæ²¡å¼€å¤šçº¿ç¨‹
        "-m",
        metavar="N",
        default=30,  # default 30 ä¸ç„¶ç½‘å‹å‘çš„å¤ªå¤šæ ¹æœ¬çˆ¬ä¸åˆ°è‡ªå·±å‘çš„éƒ½é¡¶æ‰äº†
        type=int,
        action="store",
        required=False,
        help="æœ€å¤§çˆ¬å–é¡µé¢",
        dest="maxPages",
    )
    parser.add_argument(
        "--verbose",  # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆåºŸè¯æ¨¡å¼ï¼‰
        "-v",
        default=False,
        action="store_true",
        help="åºŸè¯æ¨¡å¼",
        dest="isVerbose",
    )
    args = parser.parse_args()
    return Configure(args.userName, args.maxPages, args.isVerbose)


def main():
    arguments = process_arguments()
    print(arguments)

    print("ğŸ¢çˆ¬è¡Œä¸­â€¦")
    for url in BASE_URLS:
        print(f"\033[0;33m{url}\033[0m")
        linklist = Crawler(url, arguments).craw()
        if len(linklist) > 0:
            print("\033[0;32m" + str(len(linklist)) + " result(s) found" + "\033[0m")
            for link in linklist:
                print(link)
        else:
            print("\033[0;31mno result found\033[0m")
        print("")
    print("ğŸ¢çˆ¬å®Œå•¦~")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print("å‡ºé”™äº†ï¼")
        print(e)
    except KeyboardInterrupt:
        print("å–æ¶ˆï¼")
